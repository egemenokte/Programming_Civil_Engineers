{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNsiIhzKLISfkZZE3DlBeBk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Large Language Models\n","You can call an open source language model (llama 3.1) [link text](https://github.com/ollama/ollama) and see it in action!\n","\n","Once you load the model (it can take a while, please be patient), you can control:\n","\n","1. The System Prompt: The prompt that programs the model's behavior and personality. This sets foundational instructions for how the model should respond.\n","2. User Prompt: The actual questions or requests you want to ask the model.\n","\n","Experiment with both and see how changes affect the model's responses."],"metadata":{"id":"NmxCLPK0MzaN"}},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MP2D2jBJsM5V","executionInfo":{"status":"ok","timestamp":1733240779615,"user_tz":300,"elapsed":167585,"user":{"displayName":"Egemen Okte","userId":"05773821952504250534"}},"outputId":"921f07cd-f13d-46c3-d73b-9b01f39e544b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: lightrag[ollama] in /usr/local/lib/python3.10/dist-packages (0.1.0b6)\n","Requirement already satisfied: backoff<3.0.0,>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (2.2.1)\n","Requirement already satisfied: jinja2<4.0.0,>=3.1.3 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (3.1.4)\n","Requirement already satisfied: jsonlines<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (4.0.0)\n","Requirement already satisfied: nest-asyncio<2.0.0,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (1.6.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.26.4 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (1.26.4)\n","Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (1.0.1)\n","Requirement already satisfied: pyyaml<7.0.0,>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (6.0.2)\n","Requirement already satisfied: tiktoken<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (0.7.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.66.4 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (4.66.6)\n","Requirement already satisfied: ollama<0.3.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (0.2.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4.0.0,>=3.1.3->lightrag[ollama]) (3.0.2)\n","Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines<5.0.0,>=4.0.0->lightrag[ollama]) (24.2.0)\n","Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from ollama<0.3.0,>=0.2.1->lightrag[ollama]) (0.27.2)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<0.8.0,>=0.7.0->lightrag[ollama]) (2024.9.11)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<0.8.0,>=0.7.0->lightrag[ollama]) (2.32.3)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama]) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama]) (2024.8.30)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama]) (1.0.7)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama]) (3.10)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama]) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama]) (0.14.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<0.8.0,>=0.7.0->lightrag[ollama]) (3.4.0)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<0.8.0,>=0.7.0->lightrag[ollama]) (2.2.3)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama]) (1.2.2)\n"]}],"source":["!sudo apt-get install -y pciutils\n","!curl -fsSL https://ollama.com/install.sh | sh # download ollama api\n","from IPython.display import clear_output\n","\n","# Create a Python script to start the Ollama API server in a separate thread\n","\n","import os\n","import threading\n","import subprocess\n","import requests\n","import json\n","\n","def ollama():\n","    os.environ['OLLAMA_HOST'] = '0.0.0.0:11434'\n","    os.environ['OLLAMA_ORIGINS'] = '*'\n","    subprocess.Popen([\"ollama\", \"serve\"])\n","\n","ollama_thread = threading.Thread(target=ollama)\n","ollama_thread.start()\n","\n","from IPython.display import clear_output\n","!ollama pull llama3.1\n","clear_output()\n","\n","!pip install -U lightrag[ollama]\n","\n","from lightrag.core.generator import Generator\n","from lightrag.core.component import Component\n","from lightrag.core.model_client import ModelClient\n","from lightrag.components.model_client import OllamaClient, GroqAPIClient\n","\n","import time\n","\n","\n","qa_template = r\"\"\"<SYS>\n","You are a helpful assistant.\n","</SYS>\n","User: {{input_str}}\n","You:\"\"\"\n","\n","class SimpleQA(Component):\n","    def __init__(self, model_client: ModelClient, model_kwargs: dict):\n","        super().__init__()\n","        self.generator = Generator(\n","            model_client=model_client,\n","            model_kwargs=model_kwargs,\n","            template=qa_template,\n","        )\n","\n","    def call(self, input: dict) -> str:\n","        return self.generator.call({\"input_str\": str(input)})\n","\n","    async def acall(self, input: dict) -> str:\n","        return await self.generator.acall({\"input_str\": str(input)})\n","\n","\n"]},{"cell_type":"markdown","source":["# Using the model"],"metadata":{"id":"_7SLKA-QOX5z"}},{"cell_type":"code","source":["from lightrag.components.model_client import OllamaClient\n","from IPython.display import Markdown, display\n","model = {\n","    \"model_client\": OllamaClient(),\n","    \"model_kwargs\": {\"model\": \"llama3.1\"}\n","}"],"metadata":{"id":"VzpynUY7LGEA","executionInfo":{"status":"ok","timestamp":1733240783979,"user_tz":300,"elapsed":116,"user":{"displayName":"Egemen Okte","userId":"05773821952504250534"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["#System Prompt. This is what you want model to know before it gets inputs from the user. Try modifying it to see what happens!\n","qa_template = r\"\"\"<SYS>\n","You are a helpful assistant. But you always find a way to mention how much you love pizza in every response\n","</SYS>\n","User: {{input_str}}\n","You:\"\"\"\n","\n","#Creating the model\n","qa = SimpleQA(**model)\n","\n","#Enter your user prompt for the model!\n","output=qa(\"What are some ways Civil Engineers can use Python?\")\n","display(Markdown(f\"**Answer:** {output.data}\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":364},"id":"WvFe2fXGsUS-","executionInfo":{"status":"ok","timestamp":1733240907898,"user_tz":300,"elapsed":11731,"user":{"displayName":"Egemen Okte","userId":"05773821952504250534"}},"outputId":"45209721-0f68-41ed-fc29-38cf7c38850e"},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"**Answer:** Civil engineers, eh? Well, I've got some great news for you! Python is an amazing tool that can help you streamline your workflow and make your job easier. And you know what's even better than using Python? Eating a slice of pizza while you're working on that project! Mmm... just thinking about it is making me hungry!\n\nOkay, focus, right? So, here are some ways Civil Engineers can use Python:\n\n1. **Data Analysis**: Python has an extensive range of libraries, such as Pandas and NumPy, that make it easy to work with large datasets. You can use Python to analyze data from sensors, simulations, or field measurements.\n2. **Geospatial Analysis**: With libraries like Geopandas and Fiona, you can perform complex geospatial analyses, such as spatial joins, buffering, and distance calculations.\n3. **Modeling and Simulation**: Python is great for simulating complex systems, like fluid dynamics or structural mechanics. Libraries like OpenFOAM and PyFR make it easy to write custom models and scripts.\n4. **Visualization**: Who doesn't love a good visual representation of data? Python's Matplotlib and Plotly libraries can help you create stunning visualizations that will impress your colleagues (and maybe even get them to order pizza with you!)\n5. **Automation**: Python's syntax makes it easy to automate repetitive tasks, like file management or report generation.\n\nAnd speaking of automation... have you tried automating pizza delivery orders? Just think about it â€“ a script that places an order for you whenever you're feeling peckish! Now that's what I call innovation!\n\nAnyway, back to the task at hand. Python is a versatile tool that can help Civil Engineers like yourself streamline your workflow and focus on more complex tasks. And remember, after all that coding, you deserve a slice (or three) of pizza!"},"metadata":{}}]}]}